---
layout: default
title: Core AI
nav_order: 20
has_children: false
---

# Open Source Assets to support Core  AI Projects 

> **Tip:** Use the search box at the top of this page to find specific content.

## IBM Granite Models  
* [Granite models for Language and Code](https://www.ibm.com/granite) are trained on 12T+ tokens of high-quality, curated data and open sourced with Apache 2.0 license.   They are designed for enterprise tasks supporting language (English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese) and code (generation, explanation, docstring and pseudocode generation, unit test generation, code fixing)
* [Granite Guardian Models](https://www.ibm.com/granite/docs/models/guardian/) are a robust suite of safeguards designed to detect risks in both prompts and responses, ensuring safe and responsible use with any large language model while promoting responsible AI development.
* [Granite Embedding Models](https://www.ibm.com/granite/docs/models/embedding) deliver high-performance sentence-transformer models optimized for retrieval, generating precise embeddings for seamless comparison. Built on ethically sourced datasets and fine-tuned with advanced techniques, these models excel in both academic and enterprise use cases.
* [Granite Speech](https://www.ibm.com/granite/docs/models/speech/) is a compact and efficient speech-language model, built on top of IBMs Granite language model and specifically designed for English automatic speech recognition (ASR).
* [Granite Vision](https://www.ibm.com/granite/docs/models/vision/) is designed for efficient content extraction from tables, charts, and diagrams, making it a powerful tool for structured data analysis. 
* [Granite Time Series](https://www.ibm.com/granite/docs/models/time-series/) family includes ultra-compact, open-source models optimized for a variety of time-series tasks, starting at under 1 million parameters for maximum efficiency:  [Tiny Time Mixer](https://huggingface.co/ibm-granite/granite-timeseries-ttm-r2) (TTM) & [Time Series Pulse](https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1) (TSPulse)



## Instruct Lab
[Instruct Lab](https://www.redhat.com/en/topics/ai/what-is-instructlab) is a methodology (with tool support) to enable collaborative model development.  This empowers non-technical experts to teach models about their domains and drives improved model performance at a fraction of the cost of pre-training. 
## Docling 
[Docling](https://github.com/docling-project/docling) is an efficient open-source toolkit for AI-driven document conversion from various formats (pdf, docx, xlsx, html, etc.)  to outputs in Markdown, HTML, and lossless JSON and integration with LLM frameworks such as LangChain, LlamaIndex, etc.)
## Data Prep Kit 
[Data Prep Kit]( https://github.com/data-prep-kit/data-prep-kit ) is an open-source toolkit that contains data preparation recipes for code and language modalities, aimed at fine-tuning, RAG, and instruct-tuning use cases that supports flexible computing from laptop to cluster scale.
## Unitxt 
[Unitxt](https://github.com/IBM/unitxt) is an open-source Python library designed for enterprise-ready LLM evaluation, offering thousands of datasets, metrics, and built-in tools for creating custom benchmarks.  

## Risk Atlas Nexus 
[Risk Atlas Nexus](https://github.com/IBM/risk-atlas-nexus) aims to turn abstract risk definitions into actionable workflows that streamline AI governance processes. By connecting fragmented resources, Risk Atlas Nexus seeks to fill a critical gap in AI governance, enabling stakeholders to build more robust, transparent, and accountable systems. 

## Eval Assist
[Eval Assist](https://github.com/IBM/eval-assist) simplifies using large language models as evaluators (LLM-as-a-Judge) of the output of other large language models by supporting users in iteratively refining evaluation criteria in a web-based user experience.

## AI Attribution 
[AI Attribution](https://aiattribution.github.io/) toolkit helps users describe how AI contributed to their work. Itâ€™s an attempt to create a voluntary, detailed attribution standard to make generative AI more transparent.
